# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Overview

PaperclipMaximiser is an AI agent evaluation framework focused on testing Large Language Model (LLM) capabilities in a simulated factory-building environment based on Factorio. The framework evaluates how well AI models can reason, plan, and execute complex engineering tasks like resource extraction, processing, and factory design.

## Key Commands

### Running Evaluations

```bash
# Run independent agent evaluations
python -m eval.open.independent_runs.run --run_config=eval/open/independent_runs/run_config.json

# Run beam search evaluations
python -m eval.open.beam.run

# Run MCTS evaluations (Monte Carlo Tree Search)
python -m eval.open.mcts.main

# Run MCTS evaluations with specific objective-based approach
python -m eval.open.mcts.__main__objective_mcts
```

### Running Visualizations and Analysis

```bash
# Run visualization for factory production data
python -m eval.open.plots.run_visualiser

# Generate production volume figures
python -m eval.open.plots.visualise_production_figures

# Analyze progression
python -m eval.open.plots.simple_progression_analyser
```

## Core Architecture

The codebase consists of several key components:

### 1. Evaluation Framework

- `Evaluator` (`eval/evaluator.py`): Core evaluation logic for LLM-generated programs
- `SimpleFactorioEvaluator` (`eval/open/independent_runs/simple_evaluator.py`): A streamlined version for evaluating individual agent runs

### 2. Task Definition System

- `TaskABC` (`eval/tasks/task_abc.py`): Abstract base class for defining evaluation tasks
- `ThroughputTask` (`eval/tasks/throughput_task.py`): Evaluates ability to achieve specific production targets
- Task definitions in JSON format inside `eval/tasks/task_definitions/`

### 3. Search Algorithms

- `MCTS` (`eval/open/mcts/mcts.py`): Monte Carlo Tree Search for exploring possible factory automation strategies
- `BeamSearch` (`eval/open/beam/beam_search.py`): Fixed-compute search for direct model comparison
- Various samplers in `eval/open/mcts/samplers/` for different sampling strategies

### 4. Agent System

- `BasicAgent`: Simple LLM-based agent using models like Claude
- Support for both single-agent and multi-agent evaluations

### 5. Factorio Environment

- `FactorioInstance`: Interface to the simulated Factorio environment
- `GameState`: Representation of the game state (entities, inventory)
- `Program`: Container for code and evaluation data

## Working with the Codebase

### 1. Configuration

Most runs are configured via JSON files:

- Task definitions in `eval/tasks/task_definitions/`
- Run configurations in `eval/open/independent_runs/run_config.json`

Example of a run config:
```json
[
  {
    "task": "iron_plate_throughput_16",
    "model": "claude-3-5-sonnet-20241022",
    "num_agents": 1,
    "exit_on_task_success": true
  }
]
```

### 2. Evaluation Flow

1. A task is defined (e.g., "produce X iron plates per minute")
2. An LLM agent is given the task and generates Python code to build a factory
3. The code is executed in the simulated environment
4. Results are evaluated against the task objectives
5. For search algorithms (MCTS, Beam), feedback is incorporated for subsequent iterations

### 3. Key Concepts

- **Factory Automation**: Building systems with miners, furnaces, belts, inserters, power generation
- **Program Synthesis**: LLMs generating Python code to manipulate the Factorio environment
- **Search Strategies**: MCTS and beam search guide exploration and optimization
- **Evaluation Metrics**: Production throughput, factory efficiency, spatial organization
- **Simulated Environment**: A Factorio-like game environment where agents place entities and build factories

## Common Patterns

When working with the codebase, it's important to understand these recurring patterns:

1. **Factorio Entity Interaction**: Most Python code interacts with Factorio entities (miners, furnaces, belts) through a defined API that includes functions like `place_entity`, `insert_item`, etc.

2. **Search Algorithms**: Monte Carlo Tree Search (MCTS) is used extensively to explore the space of possible factory designs.

3. **Program Evaluation**: Code generated by LLMs is executed in a simulated environment and evaluated based on factory performance metrics.

4. **Multi-agent Configuration**: The system supports both single-agent and multi-agent evaluations with different configurations (e.g., distrust, free, impostor).

5. **Task Definitions**: Tasks are defined through JSON files that specify objectives (e.g., production targets) and constraints.